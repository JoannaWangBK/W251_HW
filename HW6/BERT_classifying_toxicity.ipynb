{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"BERT_classifying_toxicity.ipynb","provenance":[],"toc_visible":true},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"394eb52ec91d48e4800f47cc7e5e3845":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c8b249f7edf34d019907991bdfe8ad59","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_99b6b7a3990049329c64f2e04d3589a0","IPY_MODEL_01091bca90304c5a86f0c46c4395dad9"]}},"c8b249f7edf34d019907991bdfe8ad59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"99b6b7a3990049329c64f2e04d3589a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_68558ee1c6334633b31fb9d2c952b022","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7b3819261a2d4a9e8941ed4fb1f25b4d"}},"01091bca90304c5a86f0c46c4395dad9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7013181e9a2548ff8a75560f5294e3f9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 3.22MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4e47d9352dc54c89bc3568990c78d009"}},"68558ee1c6334633b31fb9d2c952b022":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7b3819261a2d4a9e8941ed4fb1f25b4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7013181e9a2548ff8a75560f5294e3f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4e47d9352dc54c89bc3568990c78d009":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9ae81c336d2b41a490abe4b7ec0b74b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bf27b774335844d89506eb2887bc2092","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_83fa39b5fe6843ffb013b9eb0a3beda0","IPY_MODEL_c43d082f2edc4dc8911e210adc06b94d"]}},"bf27b774335844d89506eb2887bc2092":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"83fa39b5fe6843ffb013b9eb0a3beda0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a192adf934bb44ac9ee3cb91482dcf2b","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":15000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":15000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3e7528edff8d4982be4817ac4e05c09c"}},"c43d082f2edc4dc8911e210adc06b94d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4bb6a75dbd264e2bbd24d7fd67599b45","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 15000/15000 [25:42&lt;00:00,  9.72it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_91c1e2c5ce064fc8a7b4b5b5dd143a3b"}},"a192adf934bb44ac9ee3cb91482dcf2b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3e7528edff8d4982be4817ac4e05c09c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4bb6a75dbd264e2bbd24d7fd67599b45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"91c1e2c5ce064fc8a7b4b5b5dd143a3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eeb5cb5d444a4e1a99d86dff191133cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_12b0516477794c21b7019ee4a3b13a90","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_749b2eab07c3420aa2b84ccb9da5dba3","IPY_MODEL_98eb13d9ee1c4c1b900f108a5c20b6e3"]}},"12b0516477794c21b7019ee4a3b13a90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"749b2eab07c3420aa2b84ccb9da5dba3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b2385be39e894a48a271b73873aa4c07","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7b34cf8ccc3d4c5fb530aea4ecff2d3f"}},"98eb13d9ee1c4c1b900f108a5c20b6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d7a91d38d1364702b0f6a087667d50cf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 7.63kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_74c0701aeab14fa1ad2f1d83d4845a25"}},"b2385be39e894a48a271b73873aa4c07":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7b34cf8ccc3d4c5fb530aea4ecff2d3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7a91d38d1364702b0f6a087667d50cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"74c0701aeab14fa1ad2f1d83d4845a25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19f68503f5f446d0b471e7ef46d71f3b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_045cc231c9944c81bd0a3afb5fc49513","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7da995e973aa4a8caf1ca174b4979cf6","IPY_MODEL_4e3ce4e4c43c4b88bf39d1794a976922"]}},"045cc231c9944c81bd0a3afb5fc49513":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7da995e973aa4a8caf1ca174b4979cf6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_93964db6cc0642c8aa4e2b41a2b2642c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_592c3fcb3ff74d34afad0261f2aaca91"}},"4e3ce4e4c43c4b88bf39d1794a976922":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e866cf8d1bc94efa82c463903082782d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:07&lt;00:00, 56.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d1eb7ba6179449c6bec7cc92760d28b5"}},"93964db6cc0642c8aa4e2b41a2b2642c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"592c3fcb3ff74d34afad0261f2aaca91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e866cf8d1bc94efa82c463903082782d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d1eb7ba6179449c6bec7cc92760d28b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0747ef6276664c80adcae067f3464477":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_91b150161e014b928b228635ad398d2a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_960bf235f014417894128dfcbce3736a","IPY_MODEL_cef6441409274cf196718ec25b503e9f"]}},"91b150161e014b928b228635ad398d2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"960bf235f014417894128dfcbce3736a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3b47c73deca64ab4bd705bb23c76d044","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_96261703f2554bc09d859343ce71aee1"}},"cef6441409274cf196718ec25b503e9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3469176f02fc4c0089b750d4b177a38f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [02:33&lt;00:00, 154.00s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_67ed6334391a461e8ad5b51f220b7a6a"}},"3b47c73deca64ab4bd705bb23c76d044":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"96261703f2554bc09d859343ce71aee1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3469176f02fc4c0089b750d4b177a38f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"67ed6334391a461e8ad5b51f220b7a6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"56077e07d3384f2bbeb44f804e339a93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aaa27985c5f349eeb4229d4b2a7ba492","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e816c37cebf447a18ab55adc5758542c","IPY_MODEL_2c6241fe62d14f638ea865ae1b0a52aa"]}},"aaa27985c5f349eeb4229d4b2a7ba492":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e816c37cebf447a18ab55adc5758542c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7d45a8c3cd9044a9a638a4dd1bb86e7c","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"","max":313,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":313,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_966815cf633246b7959146ed9856caee"}},"2c6241fe62d14f638ea865ae1b0a52aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_56e7492bb59543e4aa5873d3d498fa8f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 313/313 [02:33&lt;00:00,  2.38it/s, loss=0.196]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d2a1deb3578a4615a38ee3120db07964"}},"7d45a8c3cd9044a9a638a4dd1bb86e7c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"966815cf633246b7959146ed9856caee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"56e7492bb59543e4aa5873d3d498fa8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d2a1deb3578a4615a38ee3120db07964":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6b75eb5e44b4403b92d95f5eab4d95dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9177677aca9d42ea82e736e55017cc13","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d1e5b07c6a1c43469ac315e1a36ed41c","IPY_MODEL_99a5639efd9e4e6689e93965597ed9a8"]}},"9177677aca9d42ea82e736e55017cc13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d1e5b07c6a1c43469ac315e1a36ed41c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1bca0065bde3403a9cf7dc5d5883892a","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":157,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":157,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_945f7b32b6bc4073a86a0daee495775b"}},"99a5639efd9e4e6689e93965597ed9a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6e2b6235b59a4bdab78f4e3cc3d1d583","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 157/157 [04:42&lt;00:00,  1.80s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2fb10fa67355486580d109a561b5092a"}},"1bca0065bde3403a9cf7dc5d5883892a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"945f7b32b6bc4073a86a0daee495775b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6e2b6235b59a4bdab78f4e3cc3d1d583":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2fb10fa67355486580d109a561b5092a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"BwwRR4K_E4z3"},"source":["Now we will continue on the [Conversation AI](https://conversationai.github.io/) dataset seen in [week 4 homework and lab](https://github.com/MIDS-scaling-up/v2/tree/master/week04). \n","We shall use a version of pytorch BERT for classifying comments found at [https://github.com/huggingface/pytorch-pretrained-BERT](https://github.com/huggingface/pytorch-pretrained-BERT).  \n","\n","The original implementation of BERT is optimised for TPU. Google released some amazing performance improvements on TPU over GPU, for example, see [here](https://medium.com/@ranko.mosic/googles-bert-nlp-5b2bb1236d78) - *BERT relies on massive compute for pre-training ( 4 days on 4 to 16 Cloud TPUs; pre-training on 8 GPUs would take 40–70 days).*. In response, Nvidia released [apex](https://devblogs.nvidia.com/apex-pytorch-easy-mixed-precision-training/), which gave mixed precision training. Weights are stored in float32 format, but calculations, like forward and backward propagation happen in float16 - this allows these calculations to be made with a [4X speed up](https://github.com/huggingface/pytorch-pretrained-BERT/issues/149).  \n","\n","We shall apply BERT to the problem for classifiying toxicity, using apex from Nvidia. We shall compare the impact of hardware by running the model on a V100 and P100 and comparing the speed and accuracy in both cases.   \n","\n","This script relies heavily on an existing [Kaggle kernel](https://www.kaggle.com/yuval6967/toxic-bert-plain-vanila) from [yuval r](https://www.kaggle.com/yuval6967). \n","  \n","*Disclaimer: the dataset used contains text that may be considered profane, vulgar, or offensive.*"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QoAjcXt3E40A","executionInfo":{"status":"ok","timestamp":1615681060491,"user_tz":300,"elapsed":46129,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}},"outputId":"fe5b4200-c3ed-40bf-cc30-389c7234c354"},"source":["# Download the training and the test corpus\n","!wget -nv --show-progress -O data/test.csv.zip https://www.dropbox.com/s/xp6bo8yo1vbv5yg/test.csv.zip?dl=1\n","!wget -nv --show-progress -O data/train.csv.zip https://www.dropbox.com/s/xei6z41mfrcnxcd/train.csv.zip?dl=1\n","# Download the pretrained weights for bert base. \n","!wget -nv --show-progress -O data/uncased_L-12_H-768_A-12.zip \\\n","        https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n","!wget -nv --show-progress  -O data/cased_L-12_H-768_A-12.zip \\\n","        https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n","# unzip weights & conifg and remove the original zip\n","!unzip -d data/ data/cased_L-12_H-768_A-12.zip && rm data/cased_L-12_H-768_A-12.zip\n","!unzip -d data/ data/uncased_L-12_H-768_A-12.zip && rm data/uncased_L-12_H-768_A-12.zip\n","!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\rdata/test.csv.zip     0%[                    ]       0  --.-KB/s               \rdata/test.csv.zip   100%[===================>]  12.09M  --.-KB/s    in 0.07s   \n","2021-03-14 00:16:55 URL:https://ucbf2b14a7082c5fff0664d9e4ab.dl.dropboxusercontent.com/cd/0/get/BKokNEI_UR904EfI5VguJD7aStiVRq0vk2GWYEpSbDHNSRILkcYYm9j0E-1DFFbldYuY4P7tepgGHkLMavgRL-EaS5GLnK2QBJk84ZXp6BwIfWqMBdYgwI74wyGjbaFXB2gxMV1fuPvQMjckcQUITsmQ/file?dl=1 [12673607/12673607] -> \"data/test.csv.zip\" [1]\n","data/train.csv.zip  100%[===================>] 272.99M   160MB/s    in 1.7s    \n","2021-03-14 00:16:58 URL:https://uc326d350910aa37dfbc611d2733.dl.dropboxusercontent.com/cd/0/get/BKoexMySRzszT5zxctDcGpo-Pduw6upcq5iyJ7cEzvYIzdfXABoZ9V7FC-dtrX4Dt_lQqeXuXIO8rDlO2v6OVSODCLdbadnemX14bBa1dC-ygI2vJVGRZ7IvVFSwzMG3gb95KpyoJ32Pdnyxtju2-obN/file?dl=1 [286248352/286248352] -> \"data/train.csv.zip\" [1]\n","data/uncased_L-12_H 100%[===================>] 388.84M   117MB/s    in 3.3s    \n","2021-03-14 00:17:01 URL:https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip [407727028/407727028] -> \"data/uncased_L-12_H-768_A-12.zip\" [1]\n","data/cased_L-12_H-7 100%[===================>] 385.53M  72.3MB/s    in 6.0s    \n","2021-03-14 00:17:08 URL:https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip [404261442/404261442] -> \"data/cased_L-12_H-768_A-12.zip\" [1]\n","Archive:  data/cased_L-12_H-768_A-12.zip\n","replace data/cased_L-12_H-768_A-12/bert_model.ckpt.meta? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n","Archive:  data/uncased_L-12_H-768_A-12.zip\n","replace data/uncased_L-12_H-768_A-12/bert_model.ckpt.meta? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FCOS5iYxE40B","executionInfo":{"status":"ok","timestamp":1615683208084,"user_tz":300,"elapsed":251,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}},"outputId":"d8a25156-f392-4872-87fc-a8a4d5c211d8"},"source":["import sys, os\n","import numpy as np \n","import pandas as pd \n","import torch\n","import torch.nn as nn\n","import torch.utils.data\n","import torch.nn.functional as F\n","from sklearn.metrics import roc_auc_score\n","\n","%load_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","from tqdm import tqdm, tqdm_notebook\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","import warnings\n","warnings.filterwarnings(action='once')\n","import pickle\n","import shutil"],"execution_count":60,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"af_uap0iE40B","executionInfo":{"status":"ok","timestamp":1615681071665,"user_tz":300,"elapsed":237,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}}},"source":["# Let's activate CUDA for GPU based operations\n","device=torch.device('cuda')"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pg8OeeB4E40B"},"source":["Change the PATH variable to whereever your `week06/hw` directory is located.  \n","**For the final run we would like you to have a train_size of at least 1 Million rows, and a valid size of at least 500K rows. When you first run the script, feel free to work with a reduced train and valid size for speed.** "]},{"cell_type":"code","metadata":{"id":"h7YMlWN3E40B","executionInfo":{"status":"ok","timestamp":1615682968002,"user_tz":300,"elapsed":231,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}}},"source":["# In bert we need all inputs to have the same length, we will use the first 220 characters. \n","MAX_SEQUENCE_LENGTH = 220\n","SEED = 1234\n","# We shall run a single epoch (ie. one pass over the data)\n","EPOCHS = 1\n","PATH = '.'#'/root/v2/week06/hw' # /root/v2/week06/hw\"\n","DATA_DIR = os.path.join(PATH, \"data\")\n","WORK_DIR = os.path.join(PATH, \"workingdir\")\n","\n","OUT_MODEL = os.path.join(PATH, \"output\", \"model\")\n","OUT_MODEL_FILE = \"bert_pytorch_hw06.bin\"\n","OUT_MODEL_TENSORS = \"tensors_hw06.bin\"\n","\n","\n","# Validation and training sizes are here. \n","train_size= 10000 # 1000000 \n","valid_size= 5000  # 500000"],"execution_count":48,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IY3TwAf9E40C"},"source":["This should be the files you downloaded earlier when you ran `download.sh`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-PQ2cFIE40C","executionInfo":{"status":"ok","timestamp":1615681074966,"user_tz":300,"elapsed":230,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}},"outputId":"c855ff2d-3e1c-40ed-8351-585821cafef6"},"source":["os.listdir(DATA_DIR)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['cased_L-12_H-768_A-12',\n"," 'test.csv.zip',\n"," 'train.csv.zip',\n"," 'uncased_L-12_H-768_A-12']"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"DkW_zCQGE40D"},"source":["We shall install pytorch BERT implementation.   \n","If you would like to experiment with or view any code (purely optional, and not graded :) ), you can copy the files from the repo https://github.com/huggingface/pytorch-pretrained-BERT  "]},{"cell_type":"code","metadata":{"id":"ZdcVf2GWE40D","executionInfo":{"status":"ok","timestamp":1615681083419,"user_tz":300,"elapsed":229,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}}},"source":["%%capture\n","from transformers import BertModel, BertConfig, BertTokenizer, BertForSequenceClassification\n","from transformers import AdamW as BertAdam"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q_6CJYFiE40E"},"source":["We shall now load the model. When you run this, comment out the `capture` command to understand the archecture."]},{"cell_type":"code","metadata":{"id":"sJBfZlYEE40E","executionInfo":{"status":"ok","timestamp":1615681084934,"user_tz":300,"elapsed":227,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}}},"source":["%%capture\n","bert_config = BertConfig()"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8mbderWWE40E"},"source":["Bert needs a special formatting of sentences, so we have a sentence start and end token, as well as separators.   \n","Thanks to this [script](https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming) for a fast convertor of the sentences."]},{"cell_type":"code","metadata":{"id":"oj7RP-A0E40E","executionInfo":{"status":"ok","timestamp":1615681086378,"user_tz":300,"elapsed":239,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}}},"source":["def convert_lines(example, max_seq_length,tokenizer):\n","    max_seq_length -=2\n","    all_tokens = []\n","    longer = 0\n","    for text in tqdm_notebook(example):\n","        tokens_a = tokenizer.tokenize(text)\n","        if len(tokens_a)>max_seq_length:\n","            tokens_a = tokens_a[:max_seq_length]\n","            longer += 1\n","        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n","        all_tokens.append(one_token)\n","    print(longer)\n","    return np.array(all_tokens)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"78HPIomBE40F"},"source":["Now we load the BERT tokenizer and convert the sentences."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":234,"referenced_widgets":["394eb52ec91d48e4800f47cc7e5e3845","c8b249f7edf34d019907991bdfe8ad59","99b6b7a3990049329c64f2e04d3589a0","01091bca90304c5a86f0c46c4395dad9","68558ee1c6334633b31fb9d2c952b022","7b3819261a2d4a9e8941ed4fb1f25b4d","7013181e9a2548ff8a75560f5294e3f9","4e47d9352dc54c89bc3568990c78d009","9ae81c336d2b41a490abe4b7ec0b74b1","bf27b774335844d89506eb2887bc2092","83fa39b5fe6843ffb013b9eb0a3beda0","c43d082f2edc4dc8911e210adc06b94d","a192adf934bb44ac9ee3cb91482dcf2b","3e7528edff8d4982be4817ac4e05c09c","4bb6a75dbd264e2bbd24d7fd67599b45","91c1e2c5ce064fc8a7b4b5b5dd143a3b"]},"id":"_VSI9vM2E40F","executionInfo":{"status":"ok","timestamp":1615681120941,"user_tz":300,"elapsed":32529,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}},"outputId":"cc9b778b-9789-482b-982c-68a8b7846301"},"source":["%%time\n","# tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","train_all = pd.read_csv(os.path.join(DATA_DIR, \"train.csv.zip\")).sample(train_size+valid_size,random_state=SEED)\n","print('loaded %d records' % len(train_all))\n","\n","# Make sure all comment_text values are strings\n","train_all['comment_text'] = train_all['comment_text'].astype(str) \n","\n","sequences = convert_lines(train_all[\"comment_text\"].fillna(\"DUMMY_VALUE\"),MAX_SEQUENCE_LENGTH,tokenizer)\n","train_all=train_all.fillna(0)"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"394eb52ec91d48e4800f47cc7e5e3845","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","loaded 15000 records\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \"\"\"\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ae81c336d2b41a490abe4b7ec0b74b1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=15000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","358\n","CPU times: user 30.8 s, sys: 1.27 s, total: 32 s\n","Wall time: 32.3 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4-aRGBxnE40F"},"source":["Let us look at how the tokenising works in BERT, see below how it recongizes misspellings - words the model never saw. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"CsCOXUc1E40G","executionInfo":{"status":"ok","timestamp":1615681126548,"user_tz":300,"elapsed":238,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}},"outputId":"12097006-1adc-4dee-860a-650584b9b70b"},"source":["train_all[[\"comment_text\", 'target']].head()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment_text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>458232</th>\n","      <td>It's difficult for many old people to keep up ...</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>272766</th>\n","      <td>She recognized that her tiny-handed husband is...</td>\n","      <td>0.166667</td>\n","    </tr>\n","    <tr>\n","      <th>339129</th>\n","      <td>HPHY76,\\nGood for you for thinking out loud, w...</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>773565</th>\n","      <td>And I bet that in the day you expected your Je...</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>476233</th>\n","      <td>Kennedy will add a much needed and scientifica...</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             comment_text    target\n","458232  It's difficult for many old people to keep up ...  0.000000\n","272766  She recognized that her tiny-handed husband is...  0.166667\n","339129  HPHY76,\\nGood for you for thinking out loud, w...  0.000000\n","773565  And I bet that in the day you expected your Je...  0.500000\n","476233  Kennedy will add a much needed and scientifica...  0.000000"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"SKIseLmhE40G"},"source":["Lets tokenize some text (I intentionally mispelled some words to check berts subword information handling)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"He4G8aqrE40H","executionInfo":{"status":"ok","timestamp":1615681129067,"user_tz":300,"elapsed":226,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}},"outputId":"f2f9333d-5951-4f44-cc17-8abf2a0bddb0"},"source":["text = 'Hi, I am learning new things in w251 about deep learning the cloud and teh edge.'\n","tokens = tokenizer.tokenize(text)\n","' '.join(tokens)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'hi , i am learning new things in w ##25 ##1 about deep learning the cloud and te ##h edge .'"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"wXrBGLsKE40H"},"source":["Added start and end token and convert to ids. This is how it is fed into BERT."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"WpEnXsqcE40H","executionInfo":{"status":"ok","timestamp":1615681130595,"user_tz":300,"elapsed":214,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}},"outputId":"fdb77a9b-320a-45dc-99df-1121bfd356f6"},"source":["tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n","input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","' '.join(map(str, input_ids))"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'101 7632 1010 1045 2572 4083 2047 2477 1999 1059 17788 2487 2055 2784 4083 1996 6112 1998 8915 2232 3341 1012 102'"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"1qXGnY4tE40I"},"source":["When BERT converts this sentence to a torch tensor below is shape of the stored tensors.  \n","We have 12 input tensors, while the sentence tokens has length 23; where are can you see the 23 tokens in the tensors ?... **Feel free to post in slack or discuss in class**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203,"referenced_widgets":["eeb5cb5d444a4e1a99d86dff191133cb","12b0516477794c21b7019ee4a3b13a90","749b2eab07c3420aa2b84ccb9da5dba3","98eb13d9ee1c4c1b900f108a5c20b6e3","b2385be39e894a48a271b73873aa4c07","7b34cf8ccc3d4c5fb530aea4ecff2d3f","d7a91d38d1364702b0f6a087667d50cf","74c0701aeab14fa1ad2f1d83d4845a25","19f68503f5f446d0b471e7ef46d71f3b","045cc231c9944c81bd0a3afb5fc49513","7da995e973aa4a8caf1ca174b4979cf6","4e3ce4e4c43c4b88bf39d1794a976922","93964db6cc0642c8aa4e2b41a2b2642c","592c3fcb3ff74d34afad0261f2aaca91","e866cf8d1bc94efa82c463903082782d","d1eb7ba6179449c6bec7cc92760d28b5"]},"id":"azHrdPT6E40I","executionInfo":{"status":"ok","timestamp":1615681153967,"user_tz":300,"elapsed":21830,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}},"outputId":"c2a2d726-b7d3-4f8a-9f38-b2a501447390"},"source":["# put input on gpu and make prediction\n","bert = BertForSequenceClassification.from_pretrained('bert-base-uncased').cuda()\n","# bert = BertModel.from_pretrained(WORK_DIR).cuda()\n","bert_output = bert(torch.tensor([input_ids]).cuda())\n","\n","print('Sentence tokens {}'.format(tokens))\n","print('Number of tokens {}'.format(len(tokens)))\n","print('Tensor shapes : {}'.format([b.cpu().detach().numpy().shape for b in bert_output[0]]))\n","print('Number of torch tensors : {}'.format(len(bert_output[0])))"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eeb5cb5d444a4e1a99d86dff191133cb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19f68503f5f446d0b471e7ef46d71f3b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Sentence tokens ['[CLS]', 'hi', ',', 'i', 'am', 'learning', 'new', 'things', 'in', 'w', '##25', '##1', 'about', 'deep', 'learning', 'the', 'cloud', 'and', 'te', '##h', 'edge', '.', '[SEP]']\n","Number of tokens 23\n","Tensor shapes : [(2,)]\n","Number of torch tensors : 1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oX5x7ekOE40I"},"source":["As it is a binary problem, we change our target to [0,1], instead of float.   \n","We also split the dataset into a training and validation set, "]},{"cell_type":"code","metadata":{"id":"UlT58oXlE40I","executionInfo":{"status":"ok","timestamp":1615681172297,"user_tz":300,"elapsed":254,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}}},"source":["train_all['target']=(train_all['target']>=0.5).astype(float)\n","# Training data - sentences\n","X = sequences[:train_size] \n","# Target - the toxicity. \n","y = train_all[['target']].values[:train_size]\n","X_val = sequences[train_size:]                \n","y_val = train_all[['target']].values[train_size:]"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"6q2CQ2gsE40J","executionInfo":{"status":"ok","timestamp":1615681174390,"user_tz":300,"elapsed":227,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}}},"source":["test_df=train_all.tail(valid_size).copy()\n","train_df=train_all.head(train_size)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uFFNOgKVE40J"},"source":["**From here on in we would like you to run BERT.**   \n","**Please do rely on the script available -  [Kaggle kernel](https://www.kaggle.com/yuval6967/toxic-bert-plain-vanila) from [yuval r](https://www.kaggle.com/yuval6967) - for at least the first few steps up to training and prediction.**  \n","    \n","**Note, instead of using the apex in yuval's code, we would like you to use the new native [pytorch apex version](https://pytorch.org/docs/stable/amp.html).** \n","**You can see some examples of native [apex](https://pytorch.org/docs/stable/notes/amp_examples.html#typical-mixed-precision-training) here.**"]},{"cell_type":"markdown","metadata":{"id":"iQns--BME40J"},"source":["\n","**1)**   \n","**Load the training set to a training dataset. For this you need to load the X sequences and y objects to torch tensors**   \n","**You can use `torch.utils.data.TensorDataset` to input these into a train_dataset.**"]},{"cell_type":"code","metadata":{"id":"Whq1H0j7E40J","executionInfo":{"status":"ok","timestamp":1615683018996,"user_tz":300,"elapsed":230,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}}},"source":["# Training data creations\n","\n","\n","# Training data creations\n","train_dataset = torch.utils.data.TensorDataset(\n","    torch.tensor(X, dtype=torch.long), \n","    torch.tensor(y, dtype=torch.float))\n","val_dataset = torch.utils.data.TensorDataset(\n","    torch.tensor(X_val, dtype=torch.long))\n","\n","torch.save((train_dataset, val_dataset, y_val), os.path.join(OUT_MODEL, OUT_MODEL_TENSORS))"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"UY6DZAHRNo_q","executionInfo":{"status":"ok","timestamp":1615683033318,"user_tz":300,"elapsed":257,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}}},"source":["train_dataset, val_dataset, y_val = torch.load(os.path.join(OUT_MODEL, OUT_MODEL_TENSORS))\n"],"execution_count":52,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ro96jYEIE40J"},"source":["**2)**  \n","**Set your learning rate and batch size; and optionally random seeds if you want reproducable results**   \n","**Load your pretrained BERT using `BertForSequenceClassification`**   \n","**Initialise the gradients and place the model on cuda, set up your optimiser and decay parameters**\n","**note, we will not use apex like yuval. So no `amp.initialise` needed.**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7h-sk9ZDE40K","executionInfo":{"status":"ok","timestamp":1615683052851,"user_tz":300,"elapsed":232,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}},"outputId":"ccadd0ba-352c-445c-b6d8-3e117f121911"},"source":["SEED = 13\n","EPOCHS = 1\n","\n","LR = 2e-5\n","BATCH_SIZE = 32\n","accumulation_steps = 2\n","\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","\n","torch.backends.cudnn.deterministic = True\n"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f3bef53c930>"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"TBvod8XHLaHf","executionInfo":{"status":"ok","timestamp":1615683225413,"user_tz":300,"elapsed":3753,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}}},"source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=len(['target'])).cuda()\n","model = model.to(device)\n","\n","param_optimizer = list(model.named_parameters())\n","\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","    ]\n","\n","model = model.train()"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"id":"QaVTfkWpE40K"},"source":["\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QR896JQaE40K"},"source":["**3)**  \n","**Start training your model by iterating through batches in a single epoch of the data**    \n","**I copied the new amp process shown [here](https://github.com/aws/deep-learning-containers/blob/b9ccd5928fe2ecd8aafc4c1660b39fe265ed879f/test/dlc_tests/container_tests/bin/pytorch_tests/testPyTorchAMP#L31-L40) and it worked out.**   \n","A few tips on the changes needed,   \n","1) You will need to use `torch.cuda.amp.autocast()` and `torch.cuda.amp.GradScaler()` like seen in the reference code. \n","2) From yuval's code, the prediction and loss calculation must be executed with autocast (see new amp process code).      \n","3) Loss scaling, the omptimiser step and update can be taken from the new amp code, but please do the optimiser step and update with accumulation from yuval's code.     \n","4) For some reason, yuval's code, in the `y_pred` line, returns a tuple when run with autocast. Just index into the first element to get the prediction.    "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":117,"referenced_widgets":["0747ef6276664c80adcae067f3464477","91b150161e014b928b228635ad398d2a","960bf235f014417894128dfcbce3736a","cef6441409274cf196718ec25b503e9f","3b47c73deca64ab4bd705bb23c76d044","96261703f2554bc09d859343ce71aee1","3469176f02fc4c0089b750d4b177a38f","67ed6334391a461e8ad5b51f220b7a6a","56077e07d3384f2bbeb44f804e339a93","aaa27985c5f349eeb4229d4b2a7ba492","e816c37cebf447a18ab55adc5758542c","2c6241fe62d14f638ea865ae1b0a52aa","7d45a8c3cd9044a9a638a4dd1bb86e7c","966815cf633246b7959146ed9856caee","56e7492bb59543e4aa5873d3d498fa8f","d2a1deb3578a4615a38ee3120db07964"]},"id":"sxiVtMPHE40K","executionInfo":{"status":"ok","timestamp":1615683469257,"user_tz":300,"elapsed":154212,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}},"outputId":"b576ddcb-13a4-405c-c7ca-70515126af40"},"source":["optimizer = BertAdam(optimizer_grouped_parameters,lr=lr)\n","\n","scaler = torch.cuda.amp.GradScaler()\n","\n","tq = tqdm_notebook(range(EPOCHS))\n","for epoch in tq:\n","    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n","    avg_loss = 0.\n","    avg_accuracy = 0.\n","    lossf=None\n","    tk0 = tqdm_notebook(enumerate(train_loader),total=len(train_loader),leave=False)\n","    optimizer.zero_grad()   # Bug fix - thanks to @chinhuic\n","    for i,(x_batch, y_batch) in tk0:\n","        # optimizer.zero_grad()\n","        with torch.cuda.amp.autocast():\n","            y_pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)[0]\n","            loss =  F.binary_cross_entropy_with_logits(y_pred,y_batch.to(device))\n","            \n","        scaler.scale(loss).backward()\n","        \n","        if (i+1) % accumulation_steps == 0:         \n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","        if lossf:\n","            lossf = 0.98*lossf+0.02*loss.item()\n","        else:\n","            lossf = loss.item()\n","        tk0.set_postfix(loss = lossf)\n","        avg_loss += loss.item() / len(train_loader)\n","        avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>0.5) == (y_batch[:,0]>0.5).to(device)).to(torch.float) ).item()/len(train_loader)\n","\n","\n","\n","\n","\n"],"execution_count":63,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \"\"\"\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0747ef6276664c80adcae067f3464477","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56077e07d3384f2bbeb44f804e339a93","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=313.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FQt_xCrmE40L"},"source":["**4)**  \n","**Store your trained model to disk, you will need it if you choose section 8C.**"]},{"cell_type":"code","metadata":{"id":"WcAcDnfoE40M","executionInfo":{"status":"ok","timestamp":1615683512381,"user_tz":300,"elapsed":1363,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}}},"source":["output_model_file = \"bert_pytorch_10M_2.bin\"\n","torch.save(model.state_dict(), output_model_file)\n"],"execution_count":64,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nXM5j2V3E40M"},"source":["**5)**   \n","**Now make a prediction for your validation set.**  "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["6b75eb5e44b4403b92d95f5eab4d95dd","9177677aca9d42ea82e736e55017cc13","d1e5b07c6a1c43469ac315e1a36ed41c","99a5639efd9e4e6689e93965597ed9a8","1bca0065bde3403a9cf7dc5d5883892a","945f7b32b6bc4073a86a0daee495775b","6e2b6235b59a4bdab78f4e3cc3d1d583","2fb10fa67355486580d109a561b5092a"]},"id":"iEjfuYHiE40N","executionInfo":{"status":"ok","timestamp":1615683601657,"user_tz":300,"elapsed":70288,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}},"outputId":"832d50ce-e4c7-4d9f-9234-a6d0524a1c0e"},"source":["\n","model.to(device)\n","for param in model.parameters():\n","    param.requires_grad=False\n","model.eval()\n","valid_preds = np.zeros((len(X_val)))\n","valid = torch.utils.data.TensorDataset(torch.tensor(X_val,dtype=torch.long))\n","valid_loader = torch.utils.data.DataLoader(valid, batch_size=32, shuffle=False)\n","\n","tk0 = tqdm_notebook(valid_loader)\n","for i,(x_batch,)  in enumerate(tk0):\n","    pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)[0]\n","    valid_preds[i*32:(i+1)*32]=pred[:,0].detach().cpu().squeeze().numpy()\n","\n","\n"],"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":65},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":65},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  # Remove the CWD from sys.path while we load stuff.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b75eb5e44b4403b92d95f5eab4d95dd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=157.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"b-X2Uyl-E40N"},"source":["**6)**  \n","**In the yuval's kernel he get a metric based on the metric for the jigsaw competition - it is quite complicated. Instead, we would like you to measure the `AUC`, similar to how you did in homework 04. You can compare the results to HW04**  \n","*A tip, if your score is lower than homework 04 something is wrong....*"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UDOja97aE40N","executionInfo":{"status":"ok","timestamp":1615683758491,"user_tz":300,"elapsed":218,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}},"outputId":"cd7926d7-eb78-4aca-8bc8-bf369105dd9c"},"source":["def sigmoid(logits):\n","    return 1/(1 + np.exp(-logits))\n","\n","valid_preds = sigmoid(valid_preds)\n","\n","print('AUC score : {:.5f}'.format(roc_auc_score(y_val, valid_preds)))"],"execution_count":69,"outputs":[{"output_type":"stream","text":["AUC score : 0.50000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MFHGvrg4E40N"},"source":["**7)**  \n","**Can you show/print the validation sentences predicted with the highest and lowest toxicity ?**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ztS7uTlDE40N","executionInfo":{"status":"ok","timestamp":1615683815061,"user_tz":300,"elapsed":244,"user":{"displayName":"Jiacheng Wang","photoUrl":"","userId":"14511348876139961899"}},"outputId":"0c65b924-7140-4bc7-b19e-62fa3a5007d9"},"source":["top3_highest = np.argsort(valid_preds)[:-4:-1]\n","print(top3_highest)\n","\n","top3_lowest = np.argsort(valid_preds)[0:3]\n","print(top3_lowest)\n","\n","comments = train_all['comment_text'][train_size:].tolist()"],"execution_count":71,"outputs":[{"output_type":"stream","text":["[4999 1669 1662]\n","[   0 3336 3335]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vPSqZu7_E40O"},"source":["**8)**  \n","**Pick only one of the below items and complete it. The last two will take a good amount of time (and partial success on them is fine), so proceed with caution on your choice of items :)** \n","  \n","  \n","**A. Can you train on two epochs ?**\n","\n","**B. Can you change the learning rate and improve validation score ?**\n","   \n","**C. Make a prediction on the test data set with your downloaded model and submit to Kaggle to see where you score on public LB - check out [Abhishek's](https://www.kaggle.com/abhishek) script - https://www.kaggle.com/abhishek/pytorch-bert-inference . Note, you will need to fork Abhisheks kernel, swap out the weights to your downloaded weights and commit the kernel. When finalised and you get the output, there is a button to submit to the competition**  \n","  \n","**D. Get BERT running on the tx2 for a sample of the data.** \n","  \n","**E. Finally, and very challenging -- the `BertAdam` optimiser proved to be suboptimal for this task. There is a better optimiser for this dataset in this script [here](https://www.kaggle.com/cristinasierra/pretext-lstm-tuning-v3). Check out the `custom_loss` function. Can you implement it ? It means getting under the hood of the `BertForSequenceClassification` at the source repo and implementing a modified version locally .  `https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py`**"]},{"cell_type":"markdown","metadata":{"id":"otZc1mR_E40O"},"source":["### **Remember to terminate your instance at the end.**"]},{"cell_type":"code","metadata":{"id":"qHv8t3pfE40P"},"source":[""],"execution_count":null,"outputs":[]}]}